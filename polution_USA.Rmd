---
title: "La Pollution aux USA"
author: "Clément PEREON et Jules AVIGNON"
date: "2023-11-22"
output: html_document
---

```{r echo=FALSE}
library(tidyverse)
library(ggplot2)
library(fda)
library(reshape2)
library(wavethresh)
library(lubridate)
library(splines)
library(dplyr)
```

# Importation des données

```{r}
data_pollution <- read.csv("data_pollution.csv", sep=";")

data_pollution$Date.Local <- as.Date(data_pollution$Date.Local)

data_pollution <- data_pollution %>% group_by(City, Date.Local) %>% slice(1)
```

Ces données contiennent les taux dans l'air de quatre polluants mesurés journalièrement pour 30 villes (stations) aux États-Unis, entre 2000 et 2016.
<br>
Dans la suite, nous avons choisi d'étudier le NO2, car ce polluant est plus pertinent dans le contexte de la qualité de l'air, en particulier dans les zones urbaines. Les émissions de NO2 sont souvent liées aux activités de combustion, telles que le trafic automobile et les installations industrielles.

# Description et représentations informatives des données

## Statistiques descriptives

```{r}
summary(data_pollution$NO2.AQI)

ggplot(data_pollution, aes(x = NO2.AQI)) +
  geom_histogram(binwidth = 5, fill = "blue", color = "black") +
  labs(title = "Distribution de NO2.AQI", x = "NO2.AQI", y = "Fréquence")
```

On observe que les valeurs de NO2 sont majoritairement comprises entre 0 et 50 ppb (parts per billion).

## Tendance temporelle

```{r}
ggplot(data_pollution, aes(x = Date.Local, y = NO2.AQI, group = City, color = City)) +
  geom_line() +
  labs(title = "Tendance temporelle de NO2.AQI", x = "Date", y = "NO2.AQI")
```

Cette représentation est peu lisible du fait du nombre important de données et d'individus. Pour mieux les appréhender il serait judicieux d'appliquer un lissage à notre jeu de données.

Pour une meilleure visualisation, nous prenons les données de la ville de Phoenix car c'est la première ville du jeu de données.

```{r}
data_pho <- subset(data_pollution, City == "Phoenix")

ggplot(data_pho, aes(x = Date.Local, y = NO2.AQI)) +
  geom_line(color = "blue") +
  labs(title = "Tendance temporelle de NO2.AQI à Phoenix", x = "Date", y = "NO2.AQI")
```

## Identification des pics de pollution

```{r}
high_NO2_days <- data_pollution %>%
  filter(NO2.AQI > 100)  # Remplacez 'seuil' par votre valeur seuil

ggplot(data_pollution, aes(x = Date.Local, y = NO2.AQI)) +
  geom_line() +
  geom_point(data = high_NO2_days, aes(x = Date.Local, y = NO2.AQI, color = "red")) +
  labs(title = "Identification des pics de pollution de NO2.AQI", x = "Date", y = "NO2.AQI")
```

Avec le temps, on observe de moins en moins de pics de pollution.

## Corrélations avec d'autres polluants

```{r}
# Matrice de corrélation
cor_matrix <- cor(data_pollution[, c("NO2.AQI", "O3.AQI", "SO2.AQI", "CO.AQI")])
print(cor_matrix)

# Graphique de dispersion
pairs(data_pollution[, c("NO2.AQI", "O3.AQI", "SO2.AQI", "CO.AQI")])
```

On n'observe pas de relation particulière entre ces quatre polluant, mis à part entre NO2 et CO. En effet, ces deux polluants semblent corrélés positivement.


# Lissage des données

## Lissage avec Spline

On teste d'abord avec la ville de Phoenix pour tenter d'obtenir le meilleur lissage de Fourier.

```{r}
data_pho$date_num <- as.numeric(data_pho$Date.Local - min(data_pho$Date.Local))

smoothed_data <- data.frame()

nbasis_values <- c(5, 10, 15)

for (nbasis in nbasis_values) {
  splbasis <- bs(data_pho$date_num, df = nbasis, degree = 3, knots = NULL, intercept = FALSE)

  Phi <- predict(splbasis, newdata = list(x = data_pho$date_num))

  chat <- solve(crossprod(Phi), crossprod(Phi, data_pho$NO2.AQI))

  smoothed_data <- rbind(smoothed_data, data.frame(
    date = data_pho$Date.Local,
    smoothed_NO2_AQI = Phi %*% chat,
    nbasis = nbasis
  ))
}

ggplot() +
  geom_line(data = data_pho, aes(x = Date.Local, y = NO2.AQI), color = "blue", size = 1) +
  geom_line(data = smoothed_data, aes(x = date, y = smoothed_NO2_AQI, group = nbasis, color = as.factor(nbasis)), size = 1) +
  scale_color_discrete(name = "Nombre de Noeuds") +
  labs(title = "Régression spline pour la pollution NO2 à Phoenix avec différents noeuds",
       x = "Date",
       y = "NO2 AQI") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

A partir de 10 noeuds, on observe que le lissage suit bien la tendance.

## Lissage avec spline pénalisé

```{r}
lambda_values <- seq(0.1, 0.9, by = 0.1)

smoothed_data <- data.frame()

for (lambda in lambda_values) {
  fit <- smooth.spline(data_pho$date_num, data_pho$NO2.AQI, spar = 1-lambda)
  
  smoothed <- data.frame(
    date = data_pho$Date.Local,
    smoothed_NO2_AQI = predict(fit, data_pho$date_num)$y,
    spar = as.factor(1-lambda)
  )
  
  smoothed_data <- rbind(smoothed_data, smoothed)
}

ggplot(smoothed_data, aes(x = date, y = smoothed_NO2_AQI, color = spar)) +
  geom_line() +
  labs(title = "Comparaison des courbes lissées avec spline pénalisé",
       x = "Date",
       y = "NO2 AQI Lissé") +
  theme_minimal() +
  theme(legend.title = element_text(size = 10), legend.text = element_text(size = 8))
```

On n'observe pas de différence significative entre les pénalités lorsqu'elles sont inférieures à 0.5.

## Fourier

```{r}
variable_to_smooth <- data_pho$NO2.AQI

components_values <- c(50, 100, 150, 200)

smoothed_data <- data.frame()

for (n_components in components_values) {
  fft_result <- fft(variable_to_smooth)
  fft_result[(n_components + 1):(length(fft_result) - n_components)] <- 0
  
  smoothed <- Re(fft(fft_result, inverse = TRUE)) / length(fft_result)
  
  smoothed_data <- data.frame(
    date = data_pho$Date.Local, 
    smoothed_variable = smoothed, 
    components = rep(n_components, length(smoothed))
  )
  
  smoothed_data <- rbind(all_smoothed, smoothed_data)
}

ggplot() +
  geom_line(data = smoothed_data, aes(x = date, y = smoothed_variable, color = as.factor(components))) +
  scale_color_manual(values = c("red", "green", "blue", "purple")) +
  labs(title = "Comparaison des courbes lissées pour différentes valeurs de composants",
       x = "Date", y = "Variable Lissée") +
  theme_minimal() +
  theme(legend.position = "bottom")

```

Un nombre de composants égal à 100 ou 150 est, certes élevé, mais peut être justifié dans notre cas pour capturer des variations très fines dans nos données.

On applique le lissage à toutes les villes.

```{r}
variable_to_smooth <- data_pollution$NO2.AQI

n_components <- 100

smoothed_data <- data.frame()

for (city in unique(data_pollution$City)) {
  data_ville <- filter(data_pollution, City == city)
  
  fft_result <- fft(data_ville$NO2.AQI)
  fft_result[(n_components + 1):(length(fft_result) - n_components)] <- 0
  
  smoothed <- Re(fft(fft_result, inverse = TRUE)) / length(fft_result)
  
  smoothed_data <- data.frame(
    date = data_ville$Date.Local, 
    smoothed_variable = smoothed, 
    city = rep(city, length(smoothed))
  )
  
  smoothed_data <- rbind(smoothed_data, smoothed_data)
}

ggplot() +
  geom_line(data = smoothed_data, aes(x = date, y = smoothed_variable, color = city)) +
  labs(title = "Courbes Lissées pour NO2.AQI avec 100 Composants de Fourier",
       x = "Date", y = "Variable Lissée") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

## Ondelettes 

```{r eval=FALSE, include=FALSE}
# Select one of the pollutants (e.g., NO2.AQI) for analysis
pollutant_data <- data_pollution$NO2.AQI

# Trouver la longueur la plus proche de puissance de deux
length_power_of_two <- 2^ceiling(log2(length(pollutant_data)))

# Remplir avec des valeurs manquantes ou tronquer pour atteindre la longueur
pollutant_data_adjusted <- c(pollutant_data, rep(NA, length_power_of_two - length(pollutant_data)))

# Effectuer une analyse en ondelettes
wavelet_result <- wd(pollutant_data_adjusted, filter.number = 4, family = "DaubExPhase")

# Restreindre le tracé à la longueur d'origine
plot(wavelet_result, main = "Wavelet Decomposition", xlim = c(1, length(pollutant_data)))


# Plot the wavelet decomposition
plot(wavelet_result)

# Extract wavelet coefficients
coefficients <- coef(wavelet_result)

# Plot the scaling function and wavelet functions
par(mfrow=c(1,2))
matplot(coefficients[, 1], type="l", main="Scaling function")
matplot(coefficients[, 2:ncol(coefficients)], type="l", main="Wavelet functions")

# Generate random functions using wavelet coefficients
n <- 30
nbbase <- ncol(coefficients)
random_functions <- matrix(0, ncol = n, nrow = nbbase)

for (i in 1:n) {
  random_functions[, i] <- apply(t(rnorm(nbbase, 0, 1) * t(coefficients)), 1, sum)
}

# Plot multiple random functions
matplot(random_functions, type="l", main="Random Functions")
```


# Statistique exploratoire







# Analyse fonctionnelle

```{r}
data_long <- melt(data_pollution, id.vars=c("City", "Date.Local"), variable.name="Pollutant")
data_long$Date.Local <- as.Date(data_long$Date.Local)
data_long$Pollutant <- as.factor(data_long$Pollutant)

no2_data <- data_long[data_long$Pollutant == "NO2.AQI", ]
no2_fd <- smooth.spline(no2_data$Date.Local, no2_data$value, df = 10)

plot(no2_fd)


summary(no2_fd)

```

```{r}
no2_basis <- create.bspline.basis(rangeval = range(data_pollution$Date.Local), nbasis = 10)

no2_fd <- smooth.basis(argvals = data_pollution$Date.Local, y = data_pollution$NO2.AQI, fdParobj = no2_basis)

plot(no2_fd, main = "Analyse de données fonctionnelles de NO2.AQI")
```

La courbe obtenue à partir de l'analyse fonctionnelle peut montrer la tendance générale de la pollution de NO2.AQI au fil des années. On observe qu'il y a une diminution dans les niveaux de pollution.

```{r}
# Extraire le mois et l'année de la colonne Date.Local
all_smoothed$Day <- format(all_smoothed$date, "%b%d")
all_smoothed$Year <- format(all_smoothed$date, "%Y")

# Créer le nouveau data.frame avec les valeurs de NO2.AQI
new_df <- all_smoothed %>%
  pivot_wider(names_from = City, values_from = NO2.AQI)

data_2016 <- new_df[which(new_df$Year == "2016"),]
data_2016 <- column_to_rownames(data_2016, var = "Day")
data_2016 <- data_2016[, -c(1:2)]

#conversion des variables de data_2016 en numérique
data_2016 <- data_2016 %>% mutate_all(as.numeric)
data_2016 <- as.matrix(data_2016)
```


```{r}
splbasis = create.bspline.basis(c(1,365),norder=4,breaks=seq(1,365,30))
gcv = 1:21
for (i in 1:21){
  lambda = exp(i-10)
  fdparTemp = fdPar(splbasis,Lfdobj = 2,lambda=lambda)
  smoothdata = smooth.basis(1:365,data_2016,fdParobj = fdparTemp)
  gcv[i] = mean(smoothdata$gcv)
}
plot(gcv)
which.min(gcv)
```


## Représentation de Phoenix pour chaque année

```{r}
smoothed_data$Year <- format(smoothed_data$Date.Local, "%Y")
smoothed_data_NY <- smoothed_data[which(smoothed_data$City=="Phoenix"),]

ggplot(smoothed_data_NY, aes(x = as.numeric(format(Date.Local, "%j")), y = smoothed_NO2, group = Year, color = Year)) +
  geom_line() +
  labs(title = "Évolution de NO2.AQI à Phoenix (2000-2016)",
       x = "Jour de l'année",
       y = "NO2.AQI") +
  theme_minimal()

```
