---
title: "La Pollution aux USA"
author: "Clément PEREON et Jules AVIGNON"
date: "2023-11-22"
output: html_document
---

```{r echo=FALSE}
library(tidyverse)
library(ggplot2)
library(fda)
library(reshape2)
library(wavethresh)
library(lubridate)
library(splines)
library(dplyr)
```

# Importation des données

```{r}
data_pollution <- read.csv("data_pollution.csv", sep=";")

data_pollution$Date.Local <- as.Date(data_pollution$Date.Local)
```

Ces données contiennent les taux dans l'air de quatre polluants mesurés journalièrement pour 30 villes aux États-Unis, entre 2000 et 2016.
<br>
Dans la suite, nous avons choisi d'étudier le NO2, car ce polluant est plus pertinent dans le contexte de la qualité de l'air, en particulier dans les zones urbaines. Les émissions de NO2 sont souvent liées aux activités de combustion, telles que le trafic automobile et les installations industrielles.

# Description et représentations informatives des données

## Statistiques descriptives

```{r}
summary(data_pollution$NO2.AQI)

ggplot(data_pollution, aes(x = NO2.AQI)) +
  geom_histogram(binwidth = 5, fill = "blue", color = "black") +
  labs(title = "Distribution de NO2.AQI", x = "NO2.AQI", y = "Fréquence")
```

On observe que les valeurs de NO2 sont majoritairement comprises entre 0 et 50 ppb (parts per billion).

## Tendance temporelle

```{r}
ggplot(data_pollution, aes(x = Date.Local, y = NO2.AQI, group = City, color = City)) +
  geom_line() +
  labs(title = "Tendance temporelle de NO2.AQI", x = "Date", y = "NO2.AQI")
```

Cette représentation est peu lisible du fait du nombre important de données et d'individus. Pour mieux les appréhender il serait judicieux d'appliquer un lissage à notre jeu de données.

Pour une meilleure visualisation, nous prenons les données de la ville de Phoenix car c'est la première ville du jeu de données.

```{r}
data_pho <- subset(data_pollution, City == "Phoenix")

ggplot(data_pho, aes(x = Date.Local, y = NO2.AQI)) +
  geom_line(color = "blue") +
  labs(title = "Tendance temporelle de NO2.AQI à Phoenix", x = "Date", y = "NO2.AQI")
```

## Identification des pics de pollution

```{r}
high_NO2_days <- data_pollution %>%
  filter(NO2.AQI > 100)  # Remplacez 'seuil' par votre valeur seuil

ggplot(data_pollution, aes(x = Date.Local, y = NO2.AQI)) +
  geom_line() +
  geom_point(data = high_NO2_days, aes(x = Date.Local, y = NO2.AQI, color = "red")) +
  labs(title = "Identification des pics de pollution de NO2.AQI", x = "Date", y = "NO2.AQI")
```

Avec le temps, on observe de moins en moins de pics de pollution.

## Corrélations avec d'autres polluants

```{r}
# Matrice de corrélation
cor_matrix <- cor(data_pollution[, c("NO2.AQI", "O3.AQI", "SO2.AQI", "CO.AQI")])
print(cor_matrix)

# Graphique de dispersion
pairs(data_pollution[, c("NO2.AQI", "O3.AQI", "SO2.AQI", "CO.AQI")])
```

On n'observe pas de relation particulière entre ces quatre polluant, mis à part entre NO2 et CO. En effet, ces deux polluants semblent corrélés positivement.


# Lissage des données

## Fourier

On teste d'abord avec la ville de Phoenix pour tenter d'obtenir le meilleur lissage de Fourier.

```{r}
variable_to_smooth <- data_pho$NO2.AQI

components_values <- c(50, 100, 150, 200)

all_smoothed <- data.frame()

for (n_components in components_values) {
  fft_result <- fft(variable_to_smooth)
  fft_result[(n_components + 1):(length(fft_result) - n_components)] <- 0
  
  smoothed <- Re(fft(fft_result, inverse = TRUE)) / length(fft_result)
  
  smoothed_data <- data.frame(
    date = data_pho$Date.Local, 
    smoothed_variable = smoothed, 
    components = rep(n_components, length(smoothed))
  )
  
  all_smoothed <- rbind(all_smoothed, smoothed_data)
}

ggplot() +
  geom_line(data = all_smoothed, aes(x = date, y = smoothed_variable, color = as.factor(components))) +
  scale_color_manual(values = c("red", "green", "blue", "purple")) +
  labs(title = "Comparaison des courbes lissées pour différentes valeurs de composants",
       x = "Date", y = "Variable Lissée") +
  theme_minimal() +
  theme(legend.position = "bottom")

```

Un nombre de composants égal à 100 ou 150 est, certes élevé, mais peut être justifié dans notre cas pour capturer des variations très fines dans nos données.

On applique le lissage à toutes les villes.

```{r}
variable_to_smooth <- data_pollution$NO2.AQI

n_components <- 100

all_smoothed <- data.frame()

for (city in unique(data_pollution$City)) {
  data_ville <- filter(data_pollution, City == city)
  
  fft_result <- fft(data_ville$NO2.AQI)
  fft_result[(n_components + 1):(length(fft_result) - n_components)] <- 0
  
  smoothed <- Re(fft(fft_result, inverse = TRUE)) / length(fft_result)
  
  smoothed_data <- data.frame(
    date = data_ville$Date.Local, 
    smoothed_variable = smoothed, 
    city = rep(city, length(smoothed))
  )
  
  all_smoothed <- rbind(all_smoothed, smoothed_data)
}

ggplot() +
  geom_line(data = all_smoothed, aes(x = date, y = smoothed_variable, color = city)) +
  labs(title = "Courbes Lissées pour NO2.AQI avec 100 Composants de Fourier",
       x = "Date", y = "Variable Lissée") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

## Lissage avec Spline

```{r}
data_pho$date_num <- as.numeric(data_pho$Date.Local - min(data_pho$Date.Local))

all_smoothed <- data.frame()

nbasis_values <- c(5, 10, 15)

for (nbasis in nbasis_values) {
  splbasis <- bs(data_pho$date_num, df = nbasis, degree = 3, knots = NULL, intercept = FALSE)

    Phi <- predict(splbasis, newdata = list(x = data_pho$date_num))

  chat <- solve(crossprod(Phi), crossprod(Phi, data_pho$NO2.AQI))

  all_smoothed <- rbind(all_smoothed, data.frame(
    date = data_pho$Date.Local,
    smoothed_NO2_AQI = Phi %*% chat,
    nbasis = nbasis
  ))
}

ggplot() +
  geom_line(data = data_pho, aes(x = Date.Local, y = NO2.AQI), color = "blue", size = 1) +
  geom_line(data = all_smoothed, aes(x = date, y = smoothed_NO2_AQI, group = nbasis, color = as.factor(nbasis)), size = 1) +
  scale_color_discrete(name = "Nombre de Noeuds") +
  labs(title = "Régression spline pour la pollution NO2 à Phoenix avec différents noeuds",
       x = "Date",
       y = "NO2 AQI") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

A partir de 10 noeuds, on observe que le lissage suit bien la tendance.

## Lissage avec spline pénalisé

```{r}
spar_values <- seq(0.1, 0.9, by = 0.1)

all_smoothed <- data.frame()

for (spar in spar_values) {
  fit <- smooth.spline(data_pho$date_num, data_pho$NO2.AQI, spar = spar)
  
  smoothed <- data.frame(
    date = data_pho$Date.Local,
    smoothed_NO2_AQI = predict(fit, data_pho$date_num)$y,
    spar = as.factor(spar)
  )
  
  all_smoothed <- rbind(all_smoothed, smoothed)
}

ggplot(all_smoothed, aes(x = date, y = smoothed_NO2_AQI, color = spar)) +
  geom_line() +
  labs(title = "Comparaison des courbes lissées avec spline pénalisé",
       x = "Date",
       y = "NO2 AQI Lissé") +
  theme_minimal() +
  theme(legend.title = element_text(size = 10), legend.text = element_text(size = 8))
```

On n'observe pas de différence significative entre les pénalités lorsqu'elles sont inférieures à 0.5.

## Ondelettes 

```{r}
# Choisissez la ville (Phoenix par exemple)
selected_city <- "Phoenix"
city_data <- data_pollution %>% filter(City == selected_city)

# Assurez-vous que les données sont ordonnées par date
city_data <- city_data %>% arrange(Date.Local)

# Ajoutez du bruit (vous pouvez ajuster le niveau de bruit selon vos besoins)
city_data$NO2.AQI_noisy <- city_data$NO2.AQI + rnorm(n = nrow(city_data), mean = 0, sd = 5)

# Ajuster la longueur en ajoutant des zéros à la fin
length_power_of_two <- 2^ceiling(log2(length(city_data$NO2.AQI_noisy)))
padded_data <- c(city_data$NO2.AQI_noisy, rep(0, length_power_of_two - length(city_data$NO2.AQI_noisy)))

# Décomposition en ondelettes
coefs <- wd(padded_data, filter.number = 4, family = "DaubExPhase")

# Seuillage des coefficients (seuillage doux par exemple)
dsoft <- threshold(coefs, type = "soft", policy = "universal")

# Reconstruction du signal seuillé
fsoft <- wr(dsoft)

# Visualisation des résultats
plot(city_data$Date.Local, city_data$NO2.AQI_noisy, type = "l", col = "blue", main = "Débruitage en ondelettes")
lines(city_data$Date.Local, fsoft, col = "red", lty = 2)
legend("topright", c("Signal bruité", "Signal débruité"), col = c("blue", "red"), lty = 1:2)

```


# Statistique exploratoire







# Analyse fonctionnelle

```{r}
data_long <- melt(data_pollution, id.vars=c("City", "Date.Local"), variable.name="Pollutant")
data_long$Date.Local <- as.Date(data_long$Date.Local)
data_long$Pollutant <- as.factor(data_long$Pollutant)

no2_data <- data_long[data_long$Pollutant == "NO2.AQI", ]
no2_fd <- smooth.spline(no2_data$Date.Local, no2_data$value, df = 10)

plot(no2_fd)


summary(no2_fd)

```

```{r}
no2_basis <- create.bspline.basis(rangeval = range(data_pollution$Date.Local), nbasis = 10)

no2_fd <- smooth.basis(argvals = data_pollution$Date.Local, y = data_pollution$NO2.AQI, fdParobj = no2_basis)

plot(no2_fd, main = "Analyse de données fonctionnelles de NO2.AQI")
```

La courbe obtenue à partir de l'analyse fonctionnelle peut montrer la tendance générale de la pollution de NO2.AQI au fil des années. On observe qu'il y a une diminution dans les niveaux de pollution.



## Représentation de Phoenix pour chaque année

```{r}
smoothed_data$Year <- format(smoothed_data$Date.Local, "%Y")
smoothed_data_NY <- smoothed_data[which(smoothed_data$City=="Phoenix"),]

ggplot(smoothed_data_NY, aes(x = as.numeric(format(Date.Local, "%j")), y = smoothed_NO2, group = Year, color = Year)) +
  geom_line() +
  labs(title = "Évolution de NO2.AQI à Phoenix (2000-2016)",
       x = "Jour de l'année",
       y = "NO2.AQI") +
  theme_minimal()

```
