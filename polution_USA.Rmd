---
title: "La Pollution aux USA"
author: "Clément PEREON et Jules AVIGNON"
date: "2023-11-22"
output: html_document
---

```{r include=FALSE}
library(tidyverse)
library(ggplot2)
library(fda)
library(reshape2)
library(wavethresh)
library(lubridate)
library(splines)
library(dplyr)
```

# Importation des données

```{r}
data_pollution <- read.csv("data_pollution.csv", sep=";")

data_pollution$Date.Local <- as.Date(data_pollution$Date.Local)

data_pollution <- data_pollution %>% group_by(City, Date.Local) %>% slice(1)
```

Ces données contiennent les taux dans l'air de quatre polluants mesurés journalièrement pour 30 villes (stations) aux États-Unis, entre 2000 et 2016.
<br>
Dans la suite, nous avons choisi d'étudier le NO2, car ce polluant est plus pertinent dans le contexte de la qualité de l'air, en particulier dans les zones urbaines. Les émissions de NO2 sont souvent liées aux activités de combustion, telles que le trafic automobile et les installations industrielles.

# Description et représentations informatives des données

## Statistiques descriptives

```{r}
summary(data_pollution$NO2.AQI)

ggplot(data_pollution, aes(x = NO2.AQI)) +
  geom_histogram(binwidth = 5, fill = "blue", color = "black") +
  labs(title = "Distribution de NO2.AQI", x = "NO2.AQI", y = "Fréquence")
```

On observe que les valeurs de NO2 sont majoritairement comprises entre 0 et 50 ppb (parts per billion).

## Tendance temporelle

```{r}
ggplot(data_pollution, aes(x = Date.Local, y = NO2.AQI, group = City, color = City)) +
  geom_line() +
  labs(title = "Tendance temporelle de NO2.AQI", x = "Date", y = "NO2.AQI")
```

Cette représentation est peu lisible du fait du nombre important de données et d'individus. Pour mieux les appréhender il serait judicieux d'appliquer un lissage à notre jeu de données.

Pour une meilleure visualisation, nous prenons les données de la ville de Phoenix car c'est la première ville du jeu de données.

```{r}
data_pho <- subset(data_pollution, City == "Phoenix")

ggplot(data_pho, aes(x = Date.Local, y = NO2.AQI)) +
  geom_line(color = "blue") +
  labs(title = "Tendance temporelle de NO2.AQI à Phoenix", x = "Date", y = "NO2.AQI")
```

## Identification des pics de pollution

```{r}
high_NO2_days <- data_pollution %>%
  filter(NO2.AQI > 100)  # Remplacez 'seuil' par votre valeur seuil

ggplot(data_pollution, aes(x = Date.Local, y = NO2.AQI)) +
  geom_line() +
  geom_point(data = high_NO2_days, aes(x = Date.Local, y = NO2.AQI, color = "red")) +
  labs(title = "Identification des pics de pollution de NO2.AQI", x = "Date", y = "NO2.AQI")
```

Avec le temps, on observe de moins en moins de pics de pollution.

## Corrélations avec d'autres polluants

```{r}
# Matrice de corrélation
cor_matrix <- cor(data_pollution[, c("NO2.AQI", "O3.AQI", "SO2.AQI", "CO.AQI")])
print(cor_matrix)

# Graphique de dispersion
pairs(data_pollution[, c("NO2.AQI", "O3.AQI", "SO2.AQI", "CO.AQI")])
```

On n'observe pas de relation particulière entre ces quatre polluant, mis à part entre NO2 et CO. En effet, ces deux polluants semblent corrélés positivement.


# Lissage des données

## Lissage avec Spline

On teste d'abord avec la ville de Phoenix pour tenter d'obtenir le meilleur lissage de Fourier.

```{r}
data_pho$date_num <- as.numeric(data_pho$Date.Local - min(data_pho$Date.Local))

all_smoothed <- data.frame()

nbasis_values <- c(5, 10, 15)

for (nbasis in nbasis_values) {
  splbasis <- bs(data_pho$date_num, df = nbasis, degree = 3, knots = NULL, intercept = FALSE)

  Phi <- predict(splbasis, newdata = list(x = data_pho$date_num))

  chat <- solve(crossprod(Phi), crossprod(Phi, data_pho$NO2.AQI))

  all_smoothed <- rbind(all_smoothed, data.frame(
    date = data_pho$Date.Local,
    smoothed_NO2_AQI = Phi %*% chat,
    nbasis = nbasis
  ))
}

ggplot() +
  geom_line(data = data_pho, aes(x = Date.Local, y = NO2.AQI), color = "blue", size = 1) +
  geom_line(data = all_smoothed, aes(x = date, y = smoothed_NO2_AQI, group = nbasis, color = as.factor(nbasis)), size = 1) +
  scale_color_discrete(name = "Nombre de Noeuds") +
  labs(title = "Régression spline pour la pollution NO2 à Phoenix avec différents noeuds",
       x = "Date",
       y = "NO2 AQI") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

A partir de 10 noeuds, on observe que le lissage suit bien la tendance.

## Lissage avec spline pénalisé

```{r}
lambda_values <- seq(0.1, 0.9, by = 0.1)

all_smoothed <- data.frame()

for (lambda in lambda_values) {
  fit <- smooth.spline(data_pho$date_num, data_pho$NO2.AQI, spar = 1-lambda)
  
  smoothed <- data.frame(
    date = data_pho$Date.Local,
    smoothed_NO2_AQI = predict(fit, data_pho$date_num)$y,
    spar = as.factor(1-lambda)
  )
  
  all_smoothed <- rbind(all_smoothed, smoothed)
}

ggplot(all_smoothed, aes(x = date, y = smoothed_NO2_AQI, color = spar)) +
  geom_line() +
  labs(title = "Comparaison des courbes lissées avec spline pénalisé",
       x = "Date",
       y = "NO2 AQI Lissé") +
  theme_minimal() +
  theme(legend.title = element_text(size = 10), legend.text = element_text(size = 8))
```

On n'observe pas de différence significative entre les pénalités lorsqu'elles sont inférieures à 0.5.

## Fourier

```{r}
variable_to_smooth <- data_pho$NO2.AQI

components_values <- c(50, 100, 150, 200)

all_smoothed <- data.frame()

for (n_components in components_values) {
  fft_result <- fft(variable_to_smooth)
  fft_result[(n_components + 1):(length(fft_result) - n_components)] <- 0
  
  smoothed <- Re(fft(fft_result, inverse = TRUE)) / length(fft_result)
  
  smoothed_data <- data.frame(
    date = data_pho$Date.Local, 
    smoothed_variable = smoothed, 
    components = rep(n_components, length(smoothed))
  )
  
  all_smoothed <- rbind(all_smoothed, smoothed_data)
}

ggplot() +
  geom_line(data = all_smoothed, aes(x = date, y = smoothed_variable, color = as.factor(components))) +
  scale_color_manual(values = c("red", "green", "blue", "purple")) +
  labs(title = "Comparaison des courbes lissées pour différentes valeurs de composants",
       x = "Date", y = "Variable Lissée") +
  theme_minimal() +
  theme(legend.position = "bottom")

```

Un nombre de composants égal à 100 ou 150 est, certes élevé, mais peut être justifié dans notre cas pour capturer des variations très fines dans nos données.

On applique le lissage à toutes les villes.

```{r}
variable_to_smooth <- data_pollution$NO2.AQI

n_components <- 100

all_smoothed <- data.frame()

for (city in unique(data_pollution$City)) {
  data_ville <- filter(data_pollution, City == city)
  
  fft_result <- fft(data_ville$NO2.AQI)
  fft_result[(n_components + 1):(length(fft_result) - n_components)] <- 0
  
  smoothed <- Re(fft(fft_result, inverse = TRUE)) / length(fft_result)
  
  smoothed_data <- data.frame(
    date = data_ville$Date.Local, 
    smoothed_variable = smoothed, 
    city = rep(city, length(smoothed))
  )
  
  all_smoothed <- rbind(all_smoothed, smoothed_data)
}

ggplot() +
  geom_line(data = all_smoothed, aes(x = date, y = smoothed_variable, color = city)) +
  labs(title = "Courbes Lissées pour NO2.AQI avec 100 Composants de Fourier",
       x = "Date", y = "Variable Lissée") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

## Ondelettes 

```{r eval=FALSE, include=FALSE}
# Effectuer une analyse en ondelettes
wavelet_result <- wd(data_phoenix[0:8192,3], type = "wavelet")

# Restreindre le tracé à la longueur d'origine
plot(wavelet_result, main = "Wavelet Decomposition", xlim = c(0, 4096))
```

```{r}
wavelet_result
```


```{r}
# Plot the scaling function and wavelet functions
par(mfrow=c(1,2))
plot(wavelet_result$C, type="l", main="Représentation des \ncoefficients d'ondelettes")
plot(wavelet_result$D, type="l", main="Représentation des \ncoefficients d'échelle")
```


# Analyse fonctionnelle

```{r}
data_long <- melt(data_pollution, id.vars=c("City", "Date.Local"), variable.name="Pollutant")
data_long$Date.Local <- as.Date(data_long$Date.Local)
data_long$Pollutant <- as.factor(data_long$Pollutant)

no2_data <- data_long[data_long$Pollutant == "NO2.AQI", ]
no2_fd <- smooth.spline(no2_data$Date.Local, no2_data$value, df = 10)

plot(no2_fd)


summary(no2_fd)

```

```{r}
no2_basis <- create.bspline.basis(rangeval = range(data_pollution$Date.Local), nbasis = 10)

no2_fd <- smooth.basis(argvals = data_pollution$Date.Local, y = data_pollution$NO2.AQI, fdParobj = no2_basis)

plot(no2_fd, main = "Analyse de données fonctionnelles de NO2.AQI")
```

La courbe obtenue à partir de l'analyse fonctionnelle peut montrer la tendance générale de la pollution de NO2.AQI au fil des années. On observe qu'il y a une diminution dans les niveaux de pollution.

## Moyenne et variance fontionnelles

```{r}
mean_smoothed <- all_smoothed %>%
  group_by(date) %>%
  summarise(mean_smoothed_variable = mean(smoothed_variable),
            sd_smoothed_variable = sd(smoothed_variable))

ggplot() +
  geom_ribbon(data = mean_smoothed, aes(x = date, ymin = mean_smoothed_variable - sd_smoothed_variable, ymax = mean_smoothed_variable + sd_smoothed_variable), fill = "blue", alpha = 0.3) +
  geom_line(data = mean_smoothed, aes(x = date, y = mean_smoothed_variable), color = "blue", size = 1) +
  labs(title = "Moyenne et Variance fonctionnelle pour différentes valeurs de composants",
       x = "Date", y = "Variable Lissée") +
  theme_minimal() +
  theme(legend.position = "bottom")
```


## Clément

```{r}
# Extraire le mois et l'année de la colonne Date.Local
all_smoothed$Day <- format(all_smoothed$date, "%b%d")
all_smoothed$Year <- format(all_smoothed$date, "%Y")

# Créer le nouveau data.frame avec les valeurs de NO2.AQI
new_df <- all_smoothed %>%
  pivot_wider(names_from = city, values_from = smoothed_variable)

data_2015 <- new_df[which(new_df$Year == "2015"),]
data_2015 <- column_to_rownames(data_2015, var = "Day")
data_2015 <- data_2015[, -c(1:2)]

#IMPUTER LES NA PAR LES MOYENNES
#conversion des variables de data_2015 en numérique
data_2015 <- data_2015 %>% mutate_all(as.numeric)

data_2015 <- data_2015[, colSums(is.na(data_2015)) != nrow(data_2015)]

imputer <- function(col) {
  non_na_indices <- which(!is.na(col))
  for (i in which(is.na(col))) {
    precedent_non_na <- max(non_na_indices[non_na_indices < i], default = NA)
    suivant_non_na <- min(non_na_indices[non_na_indices > i], default = NA)
    col[i] <- mean(c(col[precedent_non_na], col[suivant_non_na]), na.rm = TRUE)
  }

  return(col)
}

data_2015 <- as.data.frame(apply(data_2015, 2, imputer))

data_2015 <- as.matrix(data_2015)
```


```{r}
splbasis = create.bspline.basis(c(1,365),norder=4,breaks=seq(1,365,30))
gcv = 1:21
for (i in 1:21){
  lambda = exp(i-10)
  fdparTemp = fdPar(splbasis,Lfdobj = 2,lambda=lambda)
  smoothdata = smooth.basis(1:365,data_2015,fdParobj = fdparTemp)
  gcv[i] = mean(smoothdata$gcv)
}
plot(gcv)
which.min(gcv)
```

## Représentation de Phoenix pour chaque année

```{r}
smoothed_data$Year <- format(smoothed_data$Date.Local, "%Y")
smoothed_data_NY <- smoothed_data[which(smoothed_data$City=="Phoenix"),]

ggplot(smoothed_data_NY, aes(x = as.numeric(format(Date.Local, "%j")), y = smoothed_NO2, group = Year, color = Year)) +
  geom_line() +
  labs(title = "Évolution de NO2.AQI à Phoenix (2000-2016)",
       x = "Jour de l'année",
       y = "NO2.AQI") +
  theme_minimal()

```
